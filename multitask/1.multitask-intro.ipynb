{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask intro\n",
    "\n",
    "Multitask learning is a technique in which a single model learns to perform multiple related tasks at the same time.\n",
    "\n",
    "Multitasking involves learning shared representations that can be used for multiple tasks. This is usually done by having a \"backbone\" (usually an encoder-type model) and multiple task-specific heads (decoder-type models or simple MLPs).\n",
    "Each task-specific head is trained separately using a task-specific loss, and the loss also propagates to the backbone.\n",
    "\n",
    "Advantages:\n",
    "* the backbone learns to extract better features from the input\n",
    "* multitask learning is more efficient than training multiple models\n",
    "* may lead to better generalization (similar to transfer learning)\n",
    "* reduces overfitting due to the shared representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-04T19:06:43.075505600Z",
     "start_time": "2025-06-04T19:06:43.051071400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:11:29.189842400Z",
     "start_time": "2025-06-04T19:11:29.091177800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from typing import List\n",
    "from tqdm.auto import trange, tqdm\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:06:51.090783900Z",
     "start_time": "2025-06-04T19:06:51.077952800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we have a generic multi task model\n",
    "# The backbone learns the shared representation\n",
    "\n",
    "class GenericMultitaskModel(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module, task_heads: List[nn.Module]):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.task_heads = nn.ModuleList(task_heads)\n",
    "\n",
    "    def forward(self, x: Tensor) -> List[Tensor]:\n",
    "        # backbone: input_space -> latent_shared_representation_space\n",
    "        # The backbone learns a function that transforms input data to a shared representation space with usefull features that can be used by multiple tasks\n",
    "        shared_representation = self.backbone(x)\n",
    "        task_outputs = []\n",
    "        for task_head in self.task_heads:\n",
    "            # task_output: latent_shared_representation_space -> task_output\n",
    "            task_output = task_head(shared_representation)\n",
    "            task_outputs.append(task_output)\n",
    "        return task_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a backbone and multiple task heads, and create a multitask model.\n",
    "\n",
    "We can train the multitask model similar to standard models. We just have to be aware that we have multiple model outputs, one for each task.\n",
    "\n",
    "Therefore, we have to calculate a loss function between the ground truth and the prediction for each task. Then, we aggregate the per-task losses, and backpropagate the resul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask on MNIST\n",
    "\n",
    "Task 1: classify images into digits from 0 to 9\n",
    "\n",
    "Task 2: classify images into even and odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:07:12.291066Z",
     "start_time": "2025-06-04T19:07:12.278996700Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParityMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, train):\n",
    "        self.dataset = datasets.MNIST(root=\"../data\", train=train, download=True)\n",
    "        self.transforms = v2.Compose(\n",
    "            [\n",
    "                v2.ToImage(),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize([0.1307], [0.3081], inplace=True),\n",
    "                torch.flatten,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image, label = self.dataset[i]\n",
    "        return {\n",
    "            \"data\": self.transforms(image),\n",
    "            \"digit_label\": label,\n",
    "            \"parity_label\": 0 if label % 2 == 0 else 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:11:33.178850400Z",
     "start_time": "2025-06-04T18:11:33.157732Z"
    }
   },
   "outputs": [],
   "source": [
    "backbone = nn.Sequential(\n",
    "    nn.Linear(784, 100),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "digit_task = nn.Sequential(\n",
    "    nn.Linear(100, 10),\n",
    ")\n",
    "parity_task = nn.Sequential(\n",
    "    nn.Linear(100, 2),\n",
    ")\n",
    "model = GenericMultitaskModel(backbone=backbone, task_heads=[digit_task, parity_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:12:03.597116700Z",
     "start_time": "2025-06-04T18:11:34.016581700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:18<00:00, 542kB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 218kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:03<00:00, 529kB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.27MB/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = ParityMNIST(train=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "criterion_1 = nn.CrossEntropyLoss()\n",
    "criterion_2 = nn.CrossEntropyLoss()  # Here criterion_2 is the same as criterion_1. But we can also use different loss functions.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercise 1: Write the training loop and check that each task loss is decreasing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:12:03.607832800Z",
     "start_time": "2025-06-04T18:12:03.600113600Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion_1, criterion_2, iterations):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i >= iterations:\n",
    "            break\n",
    "\n",
    "        data = batch[\"data\"]\n",
    "        task_1_labels = batch[\"digit_label\"]\n",
    "        task_2_labels = batch[\"parity_label\"]\n",
    "\n",
    "        # Complete the code!\n",
    "        loss1 = ...\n",
    "        loss2 = ...\n",
    "\n",
    "        print(\"Task 1 loss\", loss1.item())\n",
    "        print(\"Task 2 loss\", loss2.item())\n",
    "        print()\n",
    "\n",
    "        # Aggregate the two losses and backpropagate them!\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:12:03.867083Z",
     "start_time": "2025-06-04T18:12:03.606832400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 loss 2.3781790733337402\n",
      "Task 2 loss 0.717403769493103\n",
      "\n",
      "Task 1 loss 2.225315570831299\n",
      "Task 2 loss 0.6634694933891296\n",
      "\n",
      "Task 1 loss 2.139712333679199\n",
      "Task 2 loss 0.6054487824440002\n",
      "\n",
      "Task 1 loss 2.0010242462158203\n",
      "Task 2 loss 0.5551760792732239\n",
      "\n",
      "Task 1 loss 1.9586268663406372\n",
      "Task 2 loss 0.5273295640945435\n",
      "\n",
      "Task 1 loss 1.953698992729187\n",
      "Task 2 loss 0.5613130927085876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, optimizer, criterion_1, criterion_2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see something like this:\n",
    "```\n",
    "Task 1 loss 2.3236191272735596\n",
    "Task 2 loss 0.732703447341919\n",
    "\n",
    "Task 1 loss 2.310081720352173\n",
    "Task 2 loss 0.7832657098770142\n",
    "\n",
    "Task 1 loss 2.303960084915161\n",
    "Task 2 loss 0.7539554238319397\n",
    "\n",
    "Task 1 loss 2.2776031494140625\n",
    "Task 2 loss 0.6621295213699341\n",
    "\n",
    "Task 1 loss 2.299744129180908\n",
    "Task 2 loss 0.7180918455123901\n",
    "\n",
    "Task 1 loss 2.327526092529297\n",
    "Task 2 loss 0.6933788061141968\n",
    "\n",
    "Task 1 loss 2.2679240703582764\n",
    "Task 2 loss 0.6990024447441101\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<br>\n",
    "<pre>\n",
    "def train(model, dataloader, optimizer, criterion_1, criterion_2, iterations):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i >= iterations:\n",
    "            break\n",
    "        data = batch[\"data\"]\n",
    "        task_1_labels = batch[\"digit_label\"]\n",
    "        task_2_labels = batch[\"parity_label\"]\n",
    "        task_outputs = model(data)\n",
    "        loss1 = criterion_1(task_outputs[0], task_1_labels)\n",
    "        loss2 = criterion_2(task_outputs[1], task_2_labels)\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        print(\"Task 1 loss\", loss1.item())\n",
    "        print(\"Task 2 loss\", loss2.item())\n",
    "        print()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the losses are decreasing, so the model is learning both tasks.\n",
    "\n",
    "However, the first loss is decreasing faster, while the 2nd is decreasing slower. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = ...\n",
    "loss2 = ...\n",
    "# Not all tasks are equal!\n",
    "# If we sum multiple losses, the larger loss dominates the training, biasing the model towards that task\n",
    "# Sometimes, one task is more important, so we can give that task more weight\n",
    "# Sometimes, one task is easier than the other, so the model learns it faster. We need to scale down that loss to prevent overfit\n",
    "factor1 = ...\n",
    "factor2 = ...\n",
    "loss = factor1 * loss1 + factor2 * loss2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's apply what we learned and train a multitask model on MNIST. We will use a trainer and vary the parameters in order to obtain better results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        batch_size = 64,\n",
    "        val_batch_size = 500,\n",
    "        factor_1 = 1.0,\n",
    "        factor_2 = 0.5,\n",
    "\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.factor_1 = factor_1\n",
    "        self.factor_2 = factor_2\n",
    "\n",
    "        self.device = torch.accelerator.current_accelerator()\n",
    "        self.train_loader = torch.utils.data.DataLoader(ParityMNIST(train=True), shuffle=True, batch_size=self.batch_size, drop_last=True)\n",
    "        self.val_loader = torch.utils.data.DataLoader(ParityMNIST(train=False), batch_size=self.val_batch_size)\n",
    "        self.criterion_1 = nn.CrossEntropyLoss()\n",
    "        self.criterion_2 = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "\n",
    "        correct_digits = 0\n",
    "        correct_parity = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(self.train_loader, leave=False):\n",
    "            data = batch[\"data\"].to(self.device)\n",
    "            digit_labels = batch[\"digit_label\"].to(self.device)\n",
    "            parity_labels = batch[\"parity_label\"].to(self.device)\n",
    "            digit_predicted, parity_predicted = self.model(data)\n",
    "            loss_1 = self.criterion_1(digit_predicted, digit_labels) * self.factor_1\n",
    "            loss_2 = self.criterion_2(parity_predicted, parity_labels) * self.factor_2\n",
    "            loss = loss_1 + loss_2\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            correct_digits += digit_predicted.argmax(1).eq(digit_labels).sum().item()\n",
    "            correct_parity += parity_predicted.argmax(1).eq(parity_labels).sum().item()\n",
    "            total += digit_labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return 100.0 * correct_digits / total, 100.0 * correct_parity / total, total_loss / len(self.train_loader)\n",
    "\n",
    "    # @torch.no_grad()\n",
    "    @torch.inference_mode()\n",
    "    def val(self):\n",
    "        self.model.eval()\n",
    "\n",
    "        correct_digits = 0\n",
    "        correct_parity = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(self.val_loader, leave=False):\n",
    "            data = batch[\"data\"].to(self.device)\n",
    "            digit_labels = batch[\"digit_label\"].to(self.device)\n",
    "            parity_labels = batch[\"parity_label\"].to(self.device)\n",
    "            digit_predicted, parity_predicted = self.model(data)\n",
    "            loss_1 = self.criterion_1(digit_predicted, digit_labels) * self.factor_1\n",
    "            loss_2 = self.criterion_2(parity_predicted, parity_labels) * self.factor_2\n",
    "            loss = loss_1 + loss_2\n",
    "\n",
    "            correct_digits += digit_predicted.argmax(1).eq(digit_labels).sum().item()\n",
    "            correct_parity += parity_predicted.argmax(1).eq(parity_labels).sum().item()\n",
    "            total += digit_labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return 100.0 * correct_digits / total, 100.0 * correct_parity / total, total_loss / len(self.val_loader)\n",
    "\n",
    "    def run(self, epochs):\n",
    "        with trange(epochs) as tbar:\n",
    "            for _ in tbar:\n",
    "                train_digits_acc, train_parity_acc, train_loss = self.train()\n",
    "                val_digits_acc, val_parity_acc, val_loss = self.val()\n",
    "                tbar.set_description(f\"Train: {train_digits_acc:.1f}, {train_parity_acc:.1f}, {train_loss:.3f}, \"\n",
    "                                     f\"Val: {val_digits_acc:.1f}, {val_parity_acc:.1f}, {val_loss:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-04T19:18:57.014190600Z",
     "start_time": "2025-06-04T19:18:56.993193200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cf52f2dd923472dbd87f1a53c5842fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f550f8c717245e5aa701ea61850cf24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e827329155d345d080e4343971c7645a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6a2ab81c61b41d1a5630939c02ff23f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30f4c60aface49a4b85fbf2010daa516"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1858f42f9b7c4c13a744659ed64e93ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01f49814c04f444c82b987af895c5867"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1eec3ad4939b438ca794b8bd16c76046"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33bb961cfcc641eebb57d2309abd6f63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27adaf51297947a188b758837c10fec9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bc2dcc73ac140fc9b61413d49a91985"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cda1ba0442ba4758a13645b7453ea014"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de3bc61152374f4c9440d84e23f236b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f4f792ac13d4959a02b948092d9af13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ec411675bfe46289005fe4e6aeacf5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1f837a413fe466a9399c8dca49a1c63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a02e51548d64f6aaebef84c05848703"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6f29127b56d4f2085efa0c778bff99d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8833ab7f2fc4406fb2dd487ced43064c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85db79949aa843649090d381d55ed3a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55c53eed84d2452c97a41259c5e6f925"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "453f09dea54a47fd9e355979949c81f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "252d8d6dfcb64271867444c868b55759"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea071a450c4549c9885f47d2e0d19f94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "237f95b555e94c7cb2d2ffc79dcc32b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d53d23ade04e4cb6b134eedd303b0bbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "532219a2f18b4873949d23e99658b553"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33308299015142d1b084c10113076b46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23135f9140264f94a72af0a48d3aa47e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9bdfb7bb1104401937ae06021ec0f77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8c4130c06224eaa829a079aa106bbe8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf112843893c42f68a6f47edb729e72a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "747c03c4bfe64038b64d666649f99d67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "036af84e10ac4cffbe60d5987eef1c6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "581402fc438f4df0a9a00c7f154d7671"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8917a0586da4cb1ab320360423d779e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2a250a961a4420bb4458720940a9c37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c00f432d35174426986f71eb9a5de852"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceece53b3b384cfbb19a93a2b940974d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc2437d2630e403c883e7339f243f0e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29f218ed20924b87b53cea23594bce3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5c5ea7f25bd4eadb4a73780bb273a9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5ca282d29a74b02be2cf594903f1e49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0c5836ac0d840f2a2fe83bdf6d5c147"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7881370c9074ce9a0e188aff964d7b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b46a1a6b2a044e884528870e975a5d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11d34026ed444bd28c44c0cb858bc5cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c16d77da3fc488384a64e993c18d82c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b224993e3dbd4326bf85c34b34f79321"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/937 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f321568da03149c9b1d4d6c821e6dc64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c14ec2018e1d48eebcb175ad281564d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GenericMultitaskModel(\n",
    "    backbone=nn.Sequential(\n",
    "        nn.Linear(784, 100),\n",
    "        nn.ReLU(),\n",
    "    ),\n",
    "    task_heads=[\n",
    "        nn.Sequential(nn.Linear(100, 10)), nn.Sequential(nn.Linear(100, 2))\n",
    "    ]\n",
    ")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4, momentum=0.9, nesterov=True)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "Trainer(model, optimizer).run(25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-04T19:28:59.212894500Z",
     "start_time": "2025-06-04T19:19:02.565730700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bit_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
